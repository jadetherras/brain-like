{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NX-414: Brain-like computation and intelligence\n",
    "##### TA: Alessandro Marin Vargas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Challenge part 2 - VOneCornNEt\n",
    "\n",
    "## It was worth a trial - but we had not time to conclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#!{sys.executable} -m pip install gdown h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1s6caFNRpyR9m7ZM6XEv_e8mcXT3_PnHS\n",
      "To: /home/jupyter/week 5/IT_data.h5\n",
      "100%|██████████| 384M/384M [00:01<00:00, 214MB/s]  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'IT_data.h5'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import load_it_data, visualize_img\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gdown\n",
    "url = \"https://drive.google.com/file/d/1s6caFNRpyR9m7ZM6XEv_e8mcXT3_PnHS/view?usp=share_link\"\n",
    "output = \"IT_data.h5\"\n",
    "gdown.download(url, output, quiet=False, fuzzy=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '' ## Insert the folder where the data is, if you download in the same folder as this notebook then leave it blank\n",
    "\n",
    "stimulus_train, stimulus_val, stimulus_test, objects_train, objects_val, objects_test, spikes_train, spikes_val = load_it_data(path_to_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_stimulus, n_channels, img_size, _ = stimulus_train.shape\n",
    "_, n_neurons = spikes_train.shape\n",
    "print('The train dataset contains {} stimuli and {} IT neurons'.format(n_stimulus,n_neurons))\n",
    "print('Each stimulus have {} channgels (RGB)'.format(n_channels))\n",
    "print('The size of the image is {}x{}'.format(img_size,img_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_idx = 1\n",
    "\n",
    "visualize_img(stimulus_train,objects_train,stim_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_idx = 1\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Average firing rate for neuron {} (70-170 ms)'.format(neuron_idx))\n",
    "plt.plot(spikes_train[:,neuron_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packtage and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packtage\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from math import *\n",
    "from sklearn import metrics as ms\n",
    "\n",
    "from sklearn.decomposition import PCA, IncrementalPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vonenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_model = vonenet.get_model(model_arch='cornets', pretrained=True).module\n",
    "\n",
    "print(v1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(v1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "# The VOneModel was fed with normlalized images as shown below\n",
    "# Define the mean and std for normalization\n",
    "mean = [0.5, 0.5, 0.5]\n",
    "std = [0.5, 0.5, 0.5]\n",
    "\n",
    "#stimulus_train1 = stimulus_train.reshape(2592,64,-1)\n",
    "#stimulus_val1 = stimulus_val.reshape(288,64,-1)\n",
    "\n",
    "images_ = torch.from_numpy(stimulus_train)\n",
    "images2_ = torch.from_numpy(stimulus_val)\n",
    "\n",
    "# Create a normalization transform\n",
    "normalize = transforms.Normalize(mean=mean, std=std, inplace=False)\n",
    "\n",
    "# Apply the normalization transform to the tensor of images\n",
    "stimulus_train_norm = normalize(images_)\n",
    "\n",
    "stimulus_val_norm = normalize(images2_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose the model\n",
    "#model = torchvision.models.resnet50(weights = ResNet50_Weights.IMAGENET1K_V2)\n",
    "#model = torchvision.models.resnet50(weights=None)\n",
    "model = v1_model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do the batch\n",
    "dataloader_train = DataLoader(stimulus_train_norm, batch_size = 64,shuffle=True, pin_memory=True)\n",
    "dataloader_valid = DataLoader(stimulus_val_norm, batch_size = 64,shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#environment for Cornet backend\n",
    "Name = ['V2','V4','IT']\n",
    "model_layer = {'V2':model.V2,'V4':model.V4,'IT':model.IT}\n",
    "\n",
    "correlation = {'V2':[],'V4':[],'IT':[]}\n",
    "variance = {'V2':[],'V4':[],'IT':[]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function to apply the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "#function to hook the features\n",
    "def get_features():\n",
    "    def hook(model, input, output):\n",
    "        features.append(output.detach())\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that get the PCs from a layer (with the training set)\n",
    "def get_layer(name) :\n",
    "    hooked =model_layer[name].register_forward_hook(get_features())\n",
    "    \n",
    "    for batch in dataloader_train:\n",
    "        pred_res = v1_model(torch.Tensor(batch))\n",
    "    \n",
    "    hooked.remove()\n",
    "    \n",
    "    output = torch.concat(features,axis=0).detach().numpy()\n",
    "    pca.fit(output.reshape(output.shape[0],-1))\n",
    "    \n",
    "    return pca.transform(output.reshape(output.shape[0],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction that get the PCs from a layer (with the validation dataset)\n",
    "def get_validation(name) :\n",
    "    hooked =model_layer[name].register_forward_hook(get_features())\n",
    "    \n",
    "    for batch in dataloader_valid:\n",
    "        pred_res = v1_model(torch.Tensor(batch))\n",
    "    \n",
    "    hooked.remove()\n",
    "\n",
    "    output = torch.concat(features,axis=0).detach().numpy()\n",
    "    \n",
    "    return pca.transform(output.reshape(output.shape[0],-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#value is the expected neural activity and prediction is the predicted one\n",
    "#this function plot some neural activities and compute the correlation and explained variance \n",
    "#display the mean of correlation and explained variance and return two array\n",
    "\n",
    "def evaluation(value, prediction, title) :\n",
    "    \n",
    "    #plot neural activities\n",
    "    plt.figure()\n",
    "    \n",
    "    N = 5\n",
    "    fig, axs = plt.subplots(N, 1)\n",
    "\n",
    "    for n in range(N) : \n",
    "        axs[n].plot(value[:,n])\n",
    "        axs[n].plot(prediction[:,n])\n",
    "\n",
    "    plt.show()\n",
    "    plt.savefig('figure/bunch of prediction vs recording neural activity '+ title)\n",
    "\n",
    "    #compute correlation and explained variance\n",
    "    correlation = []\n",
    "    var = []\n",
    "\n",
    "    for i in range(value.shape[1]) : #each neuron\n",
    "        correlation.append(pearsonr(value[:,i],prediction[:,i])[0])\n",
    "        var.append(ms.explained_variance_score(value[:,i],prediction[:,i]))\n",
    "    \n",
    "    #plot correlation and explained variance\n",
    "    plt.figure()\n",
    "    plt.title('explained variance for each neuron '+ title)\n",
    "    plt.xlabel('neurons')\n",
    "    plt.ylabel(\"explained variance\")\n",
    "    plt.plot(var)\n",
    "    plt.show()\n",
    "    plt.savefig('figure/explained variance for each neuron '+ title)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title('correlation for each neuron '+ title)\n",
    "    plt.xlabel('neurons')\n",
    "    plt.ylabel(\"correlation\")\n",
    "    plt.plot(correlation)\n",
    "    plt.show()\n",
    "    plt.savefig('figure/correlation for each neuron '+ title)\n",
    "    \n",
    "    mCorr =np.mean(correlation)\n",
    "    mVar =np.mean(var)\n",
    "    #print the means\n",
    "    print('mean of correlation ', mCorr)\n",
    "    print('mean of explained variance ',mVar)\n",
    "    \n",
    "    #return arrays\n",
    "    return correlation,var,mCorr,mVar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## model of part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearModel = linear_model.Ridge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict neural activity layer by layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in Name :\n",
    "    print(\"On layer \"+layer)\n",
    "    \n",
    "    pca = PCA(n_components=1000)\n",
    "    features = []\n",
    "    PC_activation = get_layer(layer)\n",
    "    print(\"Done 1000 PCs for each layer activation\")\n",
    "    \n",
    "    features = []\n",
    "    PC_activation_validation = get_validation(layer)\n",
    "    print(\"Done 1000 PCs for prediction\")\n",
    "    \n",
    "    LinearModel.fit(PC_activation,spikes_train)\n",
    "    y_pred = LinearModel.predict(PC_activation_validation)\n",
    "    correlation[layer],variance[layer] = evaluation(spikes_val, y_pred, \"VOneNet \"+layer)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output does not correspond to the input shape - should be investigated"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m104",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m104"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "698955d2a440f09c139f7b7d2bd7d8c99823f6917bcec6f9238f0f39f5a39694"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
